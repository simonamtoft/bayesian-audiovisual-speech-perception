{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import binom\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import mle\n",
    "import flmp\n",
    "from libfunc import to_table_body\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data files\n",
    "file_paths = glob(\"./data/*.txt\")\n",
    "\n",
    "# load all data into a single array\n",
    "data = np.array([np.loadtxt(fname) for fname in file_paths])\n",
    "N, M, K = data.shape\n",
    "\n",
    "# define number of samples for each subject\n",
    "n_samples = 24 \n",
    "\n",
    "# number of samples for simulated data\n",
    "N_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = np.zeros((2, N, M, K))\n",
    "test_results = np.zeros((2, N, M, K))\n",
    "for n in range(N):\n",
    "    subject_data = data[n]\n",
    "    for m in range(M):\n",
    "        for k in range(K):\n",
    "            train_results[0, n, m, k], tA, tV = flmp.fit(np.ones(K*2), subject_data, 24, K, leave_out_idx=(m, k))\n",
    "            p_A, p_V, p_AV = flmp.compute_probs(tA, tV)\n",
    "            p = np.vstack([p_A.T, p_V.T, p_AV])\n",
    "            test_results[0, n, m, k] = -binom.logpmf(subject_data[m, k], 24, p[m, k])\n",
    "            \n",
    "            train_results[1, n, m, k], c_A, c_V, std_A, std_V = mle.fit(np.ones(4), subject_data, 24, leave_out_idx=(m, k))\n",
    "            p_A, p_V, p_AV = mle.compute_probs(c_A, c_V, np.exp(std_A), np.exp(std_V))\n",
    "            p = np.vstack([p_A.T, p_V.T, p_AV])\n",
    "            test_results[1, n, m, k] = -binom.logpmf(subject_data[m, k], 24, p[m, k])\n",
    "\n",
    "train_results = train_results.reshape(2, N, -1)\n",
    "test_results = test_results.reshape(2, N, -1).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">FLMP</th>\n",
       "      <th colspan=\"5\" halign=\"left\">MLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Subject 1</th>\n",
       "      <th>Subject 2</th>\n",
       "      <th>Subject 3</th>\n",
       "      <th>Subject 4</th>\n",
       "      <th>Subject 5</th>\n",
       "      <th>Subject 1</th>\n",
       "      <th>Subject 2</th>\n",
       "      <th>Subject 3</th>\n",
       "      <th>Subject 4</th>\n",
       "      <th>Subject 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.43</td>\n",
       "      <td>31.87</td>\n",
       "      <td>51.60</td>\n",
       "      <td>46.50</td>\n",
       "      <td>42.71</td>\n",
       "      <td>72.67</td>\n",
       "      <td>52.39</td>\n",
       "      <td>68.96</td>\n",
       "      <td>67.20</td>\n",
       "      <td>53.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.06</td>\n",
       "      <td>31.53</td>\n",
       "      <td>49.47</td>\n",
       "      <td>45.76</td>\n",
       "      <td>41.57</td>\n",
       "      <td>71.52</td>\n",
       "      <td>53.42</td>\n",
       "      <td>66.07</td>\n",
       "      <td>66.57</td>\n",
       "      <td>51.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.78</td>\n",
       "      <td>30.99</td>\n",
       "      <td>51.49</td>\n",
       "      <td>45.48</td>\n",
       "      <td>39.01</td>\n",
       "      <td>68.27</td>\n",
       "      <td>53.18</td>\n",
       "      <td>63.86</td>\n",
       "      <td>61.98</td>\n",
       "      <td>51.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.76</td>\n",
       "      <td>30.21</td>\n",
       "      <td>51.38</td>\n",
       "      <td>45.32</td>\n",
       "      <td>41.24</td>\n",
       "      <td>65.63</td>\n",
       "      <td>52.13</td>\n",
       "      <td>66.23</td>\n",
       "      <td>63.87</td>\n",
       "      <td>49.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.24</td>\n",
       "      <td>32.78</td>\n",
       "      <td>53.27</td>\n",
       "      <td>46.66</td>\n",
       "      <td>42.77</td>\n",
       "      <td>71.99</td>\n",
       "      <td>54.96</td>\n",
       "      <td>69.15</td>\n",
       "      <td>66.99</td>\n",
       "      <td>53.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.95</td>\n",
       "      <td>32.86</td>\n",
       "      <td>51.10</td>\n",
       "      <td>44.67</td>\n",
       "      <td>41.36</td>\n",
       "      <td>67.71</td>\n",
       "      <td>53.81</td>\n",
       "      <td>65.80</td>\n",
       "      <td>66.36</td>\n",
       "      <td>49.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.60</td>\n",
       "      <td>30.69</td>\n",
       "      <td>51.25</td>\n",
       "      <td>45.18</td>\n",
       "      <td>40.97</td>\n",
       "      <td>69.66</td>\n",
       "      <td>47.98</td>\n",
       "      <td>66.30</td>\n",
       "      <td>64.76</td>\n",
       "      <td>49.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45.95</td>\n",
       "      <td>31.94</td>\n",
       "      <td>51.83</td>\n",
       "      <td>45.09</td>\n",
       "      <td>37.56</td>\n",
       "      <td>70.14</td>\n",
       "      <td>53.98</td>\n",
       "      <td>67.76</td>\n",
       "      <td>65.26</td>\n",
       "      <td>48.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.65</td>\n",
       "      <td>32.84</td>\n",
       "      <td>50.98</td>\n",
       "      <td>44.23</td>\n",
       "      <td>41.44</td>\n",
       "      <td>72.62</td>\n",
       "      <td>55.07</td>\n",
       "      <td>68.30</td>\n",
       "      <td>64.91</td>\n",
       "      <td>52.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>46.80</td>\n",
       "      <td>32.92</td>\n",
       "      <td>52.23</td>\n",
       "      <td>44.80</td>\n",
       "      <td>41.58</td>\n",
       "      <td>72.80</td>\n",
       "      <td>55.08</td>\n",
       "      <td>66.96</td>\n",
       "      <td>62.45</td>\n",
       "      <td>53.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47.30</td>\n",
       "      <td>32.99</td>\n",
       "      <td>51.62</td>\n",
       "      <td>46.88</td>\n",
       "      <td>42.81</td>\n",
       "      <td>72.64</td>\n",
       "      <td>55.04</td>\n",
       "      <td>67.93</td>\n",
       "      <td>67.21</td>\n",
       "      <td>53.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47.22</td>\n",
       "      <td>32.97</td>\n",
       "      <td>52.78</td>\n",
       "      <td>44.25</td>\n",
       "      <td>42.79</td>\n",
       "      <td>71.69</td>\n",
       "      <td>54.68</td>\n",
       "      <td>67.06</td>\n",
       "      <td>64.71</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47.06</td>\n",
       "      <td>32.90</td>\n",
       "      <td>51.09</td>\n",
       "      <td>42.76</td>\n",
       "      <td>41.17</td>\n",
       "      <td>67.90</td>\n",
       "      <td>52.66</td>\n",
       "      <td>65.38</td>\n",
       "      <td>65.95</td>\n",
       "      <td>51.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45.03</td>\n",
       "      <td>31.08</td>\n",
       "      <td>51.56</td>\n",
       "      <td>45.04</td>\n",
       "      <td>40.79</td>\n",
       "      <td>70.98</td>\n",
       "      <td>49.95</td>\n",
       "      <td>67.61</td>\n",
       "      <td>65.39</td>\n",
       "      <td>50.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45.35</td>\n",
       "      <td>30.88</td>\n",
       "      <td>52.13</td>\n",
       "      <td>45.37</td>\n",
       "      <td>41.74</td>\n",
       "      <td>69.50</td>\n",
       "      <td>49.39</td>\n",
       "      <td>67.56</td>\n",
       "      <td>65.72</td>\n",
       "      <td>52.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.40</td>\n",
       "      <td>30.46</td>\n",
       "      <td>51.65</td>\n",
       "      <td>46.79</td>\n",
       "      <td>40.67</td>\n",
       "      <td>68.51</td>\n",
       "      <td>52.60</td>\n",
       "      <td>66.76</td>\n",
       "      <td>67.20</td>\n",
       "      <td>48.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>43.08</td>\n",
       "      <td>30.90</td>\n",
       "      <td>51.20</td>\n",
       "      <td>46.57</td>\n",
       "      <td>41.77</td>\n",
       "      <td>69.36</td>\n",
       "      <td>52.21</td>\n",
       "      <td>67.61</td>\n",
       "      <td>66.84</td>\n",
       "      <td>52.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45.39</td>\n",
       "      <td>29.94</td>\n",
       "      <td>50.69</td>\n",
       "      <td>45.89</td>\n",
       "      <td>40.68</td>\n",
       "      <td>69.69</td>\n",
       "      <td>53.17</td>\n",
       "      <td>64.83</td>\n",
       "      <td>62.41</td>\n",
       "      <td>51.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40.54</td>\n",
       "      <td>26.75</td>\n",
       "      <td>50.64</td>\n",
       "      <td>44.93</td>\n",
       "      <td>41.81</td>\n",
       "      <td>70.62</td>\n",
       "      <td>52.98</td>\n",
       "      <td>67.69</td>\n",
       "      <td>63.54</td>\n",
       "      <td>50.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>43.92</td>\n",
       "      <td>32.91</td>\n",
       "      <td>53.29</td>\n",
       "      <td>45.88</td>\n",
       "      <td>42.78</td>\n",
       "      <td>71.53</td>\n",
       "      <td>53.64</td>\n",
       "      <td>68.44</td>\n",
       "      <td>66.09</td>\n",
       "      <td>53.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45.48</td>\n",
       "      <td>30.78</td>\n",
       "      <td>51.45</td>\n",
       "      <td>46.61</td>\n",
       "      <td>42.16</td>\n",
       "      <td>68.63</td>\n",
       "      <td>53.00</td>\n",
       "      <td>65.31</td>\n",
       "      <td>67.17</td>\n",
       "      <td>53.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45.48</td>\n",
       "      <td>30.92</td>\n",
       "      <td>51.06</td>\n",
       "      <td>46.06</td>\n",
       "      <td>41.49</td>\n",
       "      <td>69.75</td>\n",
       "      <td>53.28</td>\n",
       "      <td>67.58</td>\n",
       "      <td>66.11</td>\n",
       "      <td>52.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45.71</td>\n",
       "      <td>31.46</td>\n",
       "      <td>51.46</td>\n",
       "      <td>45.64</td>\n",
       "      <td>40.25</td>\n",
       "      <td>71.09</td>\n",
       "      <td>52.75</td>\n",
       "      <td>67.70</td>\n",
       "      <td>62.02</td>\n",
       "      <td>51.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>47.23</td>\n",
       "      <td>32.91</td>\n",
       "      <td>51.98</td>\n",
       "      <td>45.31</td>\n",
       "      <td>40.99</td>\n",
       "      <td>70.96</td>\n",
       "      <td>54.69</td>\n",
       "      <td>68.24</td>\n",
       "      <td>64.00</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47.29</td>\n",
       "      <td>32.98</td>\n",
       "      <td>53.36</td>\n",
       "      <td>46.57</td>\n",
       "      <td>42.81</td>\n",
       "      <td>72.49</td>\n",
       "      <td>55.04</td>\n",
       "      <td>69.17</td>\n",
       "      <td>66.59</td>\n",
       "      <td>53.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45.50</td>\n",
       "      <td>31.32</td>\n",
       "      <td>51.07</td>\n",
       "      <td>45.87</td>\n",
       "      <td>41.04</td>\n",
       "      <td>70.48</td>\n",
       "      <td>52.80</td>\n",
       "      <td>64.71</td>\n",
       "      <td>65.11</td>\n",
       "      <td>49.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>44.87</td>\n",
       "      <td>32.00</td>\n",
       "      <td>47.79</td>\n",
       "      <td>45.20</td>\n",
       "      <td>41.23</td>\n",
       "      <td>70.77</td>\n",
       "      <td>54.02</td>\n",
       "      <td>66.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>51.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>45.92</td>\n",
       "      <td>32.78</td>\n",
       "      <td>51.81</td>\n",
       "      <td>45.12</td>\n",
       "      <td>41.00</td>\n",
       "      <td>71.47</td>\n",
       "      <td>54.99</td>\n",
       "      <td>67.98</td>\n",
       "      <td>63.35</td>\n",
       "      <td>51.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>47.28</td>\n",
       "      <td>32.98</td>\n",
       "      <td>53.21</td>\n",
       "      <td>42.71</td>\n",
       "      <td>40.37</td>\n",
       "      <td>72.53</td>\n",
       "      <td>55.07</td>\n",
       "      <td>68.87</td>\n",
       "      <td>65.77</td>\n",
       "      <td>52.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>47.31</td>\n",
       "      <td>32.99</td>\n",
       "      <td>53.37</td>\n",
       "      <td>46.84</td>\n",
       "      <td>42.81</td>\n",
       "      <td>72.77</td>\n",
       "      <td>55.08</td>\n",
       "      <td>69.37</td>\n",
       "      <td>67.02</td>\n",
       "      <td>53.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>45.29</td>\n",
       "      <td>30.87</td>\n",
       "      <td>50.06</td>\n",
       "      <td>44.69</td>\n",
       "      <td>41.17</td>\n",
       "      <td>67.52</td>\n",
       "      <td>45.61</td>\n",
       "      <td>66.64</td>\n",
       "      <td>59.17</td>\n",
       "      <td>52.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>45.58</td>\n",
       "      <td>32.52</td>\n",
       "      <td>50.95</td>\n",
       "      <td>45.12</td>\n",
       "      <td>41.08</td>\n",
       "      <td>67.45</td>\n",
       "      <td>55.06</td>\n",
       "      <td>67.78</td>\n",
       "      <td>64.94</td>\n",
       "      <td>50.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>45.80</td>\n",
       "      <td>32.89</td>\n",
       "      <td>51.95</td>\n",
       "      <td>45.03</td>\n",
       "      <td>41.27</td>\n",
       "      <td>71.06</td>\n",
       "      <td>55.08</td>\n",
       "      <td>66.49</td>\n",
       "      <td>64.41</td>\n",
       "      <td>51.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>47.30</td>\n",
       "      <td>32.98</td>\n",
       "      <td>53.25</td>\n",
       "      <td>45.36</td>\n",
       "      <td>42.75</td>\n",
       "      <td>72.78</td>\n",
       "      <td>55.08</td>\n",
       "      <td>69.29</td>\n",
       "      <td>66.22</td>\n",
       "      <td>53.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>47.32</td>\n",
       "      <td>32.99</td>\n",
       "      <td>53.37</td>\n",
       "      <td>46.88</td>\n",
       "      <td>42.81</td>\n",
       "      <td>72.80</td>\n",
       "      <td>55.08</td>\n",
       "      <td>69.41</td>\n",
       "      <td>67.16</td>\n",
       "      <td>53.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FLMP                                               MLE            \\\n",
       "   Subject 1 Subject 2 Subject 3 Subject 4 Subject 5 Subject 1 Subject 2   \n",
       "1      46.43     31.87     51.60     46.50     42.71     72.67     52.39   \n",
       "2      46.06     31.53     49.47     45.76     41.57     71.52     53.42   \n",
       "3      45.78     30.99     51.49     45.48     39.01     68.27     53.18   \n",
       "4      44.76     30.21     51.38     45.32     41.24     65.63     52.13   \n",
       "5      46.24     32.78     53.27     46.66     42.77     71.99     54.96   \n",
       "6      45.95     32.86     51.10     44.67     41.36     67.71     53.81   \n",
       "7      45.60     30.69     51.25     45.18     40.97     69.66     47.98   \n",
       "8      45.95     31.94     51.83     45.09     37.56     70.14     53.98   \n",
       "9      46.65     32.84     50.98     44.23     41.44     72.62     55.07   \n",
       "10     46.80     32.92     52.23     44.80     41.58     72.80     55.08   \n",
       "11     47.30     32.99     51.62     46.88     42.81     72.64     55.04   \n",
       "12     47.22     32.97     52.78     44.25     42.79     71.69     54.68   \n",
       "13     47.06     32.90     51.09     42.76     41.17     67.90     52.66   \n",
       "14     45.03     31.08     51.56     45.04     40.79     70.98     49.95   \n",
       "15     45.35     30.88     52.13     45.37     41.74     69.50     49.39   \n",
       "16     44.40     30.46     51.65     46.79     40.67     68.51     52.60   \n",
       "17     43.08     30.90     51.20     46.57     41.77     69.36     52.21   \n",
       "18     45.39     29.94     50.69     45.89     40.68     69.69     53.17   \n",
       "19     40.54     26.75     50.64     44.93     41.81     70.62     52.98   \n",
       "20     43.92     32.91     53.29     45.88     42.78     71.53     53.64   \n",
       "21     45.48     30.78     51.45     46.61     42.16     68.63     53.00   \n",
       "22     45.48     30.92     51.06     46.06     41.49     69.75     53.28   \n",
       "23     45.71     31.46     51.46     45.64     40.25     71.09     52.75   \n",
       "24     47.23     32.91     51.98     45.31     40.99     70.96     54.69   \n",
       "25     47.29     32.98     53.36     46.57     42.81     72.49     55.04   \n",
       "26     45.50     31.32     51.07     45.87     41.04     70.48     52.80   \n",
       "27     44.87     32.00     47.79     45.20     41.23     70.77     54.02   \n",
       "28     45.92     32.78     51.81     45.12     41.00     71.47     54.99   \n",
       "29     47.28     32.98     53.21     42.71     40.37     72.53     55.07   \n",
       "30     47.31     32.99     53.37     46.84     42.81     72.77     55.08   \n",
       "31     45.29     30.87     50.06     44.69     41.17     67.52     45.61   \n",
       "32     45.58     32.52     50.95     45.12     41.08     67.45     55.06   \n",
       "33     45.80     32.89     51.95     45.03     41.27     71.06     55.08   \n",
       "34     47.30     32.98     53.25     45.36     42.75     72.78     55.08   \n",
       "35     47.32     32.99     53.37     46.88     42.81     72.80     55.08   \n",
       "\n",
       "                                  \n",
       "   Subject 3 Subject 4 Subject 5  \n",
       "1      68.96     67.20     53.55  \n",
       "2      66.07     66.57     51.96  \n",
       "3      63.86     61.98     51.64  \n",
       "4      66.23     63.87     49.95  \n",
       "5      69.15     66.99     53.49  \n",
       "6      65.80     66.36     49.55  \n",
       "7      66.30     64.76     49.88  \n",
       "8      67.76     65.26     48.63  \n",
       "9      68.30     64.91     52.26  \n",
       "10     66.96     62.45     53.53  \n",
       "11     67.93     67.21     53.55  \n",
       "12     67.06     64.71     53.40  \n",
       "13     65.38     65.95     51.12  \n",
       "14     67.61     65.39     50.44  \n",
       "15     67.56     65.72     52.56  \n",
       "16     66.76     67.20     48.42  \n",
       "17     67.61     66.84     52.46  \n",
       "18     64.83     62.41     51.28  \n",
       "19     67.69     63.54     50.31  \n",
       "20     68.44     66.09     53.33  \n",
       "21     65.31     67.17     53.49  \n",
       "22     67.58     66.11     52.28  \n",
       "23     67.70     62.02     51.68  \n",
       "24     68.24     64.00     52.43  \n",
       "25     69.17     66.59     53.51  \n",
       "26     64.71     65.11     49.82  \n",
       "27     66.18     65.17     51.80  \n",
       "28     67.98     63.35     51.74  \n",
       "29     68.87     65.77     52.28  \n",
       "30     69.37     67.02     53.54  \n",
       "31     66.64     59.17     52.55  \n",
       "32     67.78     64.94     50.73  \n",
       "33     66.49     64.41     51.57  \n",
       "34     69.29     66.22     53.45  \n",
       "35     69.41     67.16     53.55  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flmp_df = pd.DataFrame(train_results[0].T, columns=[f\"Subject {i+1}\" for i in range(N)])\n",
    "mle_df = pd.DataFrame(train_results[1].T, columns=[f\"Subject {i+1}\" for i in range(N)])\n",
    "\n",
    "df = pd.concat([flmp_df, mle_df], join='outer', axis=1, keys=[\"FLMP\", \"MLE\"]).round(2)\n",
    "df.index = df.index + 1\n",
    "df.to_latex(\"nice_table.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66.69455697, 338.13813799,  87.8587574 ,  57.38571673,\n",
       "        70.46966326])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLMP</th>\n",
       "      <th>MLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subject 1</th>\n",
       "      <td>66.69</td>\n",
       "      <td>89.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject 2</th>\n",
       "      <td>338.14</td>\n",
       "      <td>73.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject 3</th>\n",
       "      <td>87.86</td>\n",
       "      <td>80.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject 4</th>\n",
       "      <td>57.39</td>\n",
       "      <td>79.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject 5</th>\n",
       "      <td>70.47</td>\n",
       "      <td>64.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FLMP    MLE\n",
       "Subject 1   66.69  89.30\n",
       "Subject 2  338.14  73.01\n",
       "Subject 3   87.86  80.73\n",
       "Subject 4   57.39  79.65\n",
       "Subject 5   70.47  64.84"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flmp_df = pd.DataFrame(test_results[0])\n",
    "mle_df = pd.DataFrame(test_results[1])\n",
    "\n",
    "df = pd.concat([flmp_df, mle_df], join='outer', axis=1).round(2)\n",
    "df.columns = [\"FLMP\", \"MLE\"]\n",
    "df.index = [f\"Subject {i+1}\" for i in range(N)]\n",
    "df.to_latex(\"nice_table_2.txt\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d8026c75a4908d7e0e048edfdade2cb3b8819d75b067a00cc154c2b5f826605"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
