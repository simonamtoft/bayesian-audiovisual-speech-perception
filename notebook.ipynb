{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import binom\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "data_dir = \"data\"\n",
    "file_paths = glob(path.join(data_dir, \"*.txt\"))\n",
    "\n",
    "# N x M x K\n",
    "# 5 FILES x 7 ROWS  x 5 COLUMNS\n",
    "# ROW 1: Audio \n",
    "# ROW 2: Visual\n",
    "# ROW 3-7: Visual going from 'b' (row 3) to 'd' (row 7)\n",
    "# Columns: Audio from 'b' (col 1) to 'd' (col 5)\n",
    "data = np.array([np.loadtxt(fname) for fname in file_paths], dtype=np.int64)\n",
    "N, M, K = data.shape\n",
    "\n",
    "AUDIO_DATA       = data[:, 0, :]\n",
    "VISUAL_DATA      = data[:, 1, :]\n",
    "AUDIOVISUAL_DATA = data[:, 2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_softmax(theta):\n",
    "    e = np.exp(theta)\n",
    "    return e / (e +1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_pmf(k, n, p):\n",
    "    return comb(n, k) * np.power(p, k) * np.power(1 - p, n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (data[0], 24, np.vstack([p_a.T, p_v.T, p_av]))\n",
    "np.isclose(binom.logpmf(*args), np.log(binomial_pmf(*args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(theta, subject_data):\n",
    "    theta_a = theta[0:K]\n",
    "    theta_v = theta[K: ]\n",
    "\n",
    "    p_a = np.array([baseline_softmax(theta) for theta in theta_a]).reshape(-1,1)\n",
    "    p_v = np.array([baseline_softmax(theta) for theta in theta_v]).reshape(-1,1)\n",
    "    \n",
    "    # Outer product for all combinations\n",
    "    p_av = (p_a @ p_v.T) / (p_a @ p_v.T + (1 - p_a) @ (1 - p_v).T)\n",
    "    # likelihoods = binom.logpmf(subject_data, 24, np.vstack([p_a.T, p_v.T, p_av]))\n",
    "    likelihoods = np.log(binomial_pmf(subject_data, 24, np.vstack([p_a.T, p_v.T, p_av])))\n",
    "\n",
    "    return -(likelihoods.sum())\n",
    "\n",
    "theta_set = []\n",
    "p_set = []\n",
    "for i in range(5):\n",
    "    \n",
    "    theta = np.random.randn(K*2)\n",
    "    opt_result = minimize(objective_function, theta, args=(data[i]))\n",
    "    objective, theta_a, theta_v, success = (\n",
    "        opt_result.fun, \n",
    "        (opt_result.x[0:K]), \n",
    "        (opt_result.x[K:]), \n",
    "        opt_result.success\n",
    "    )\n",
    "\n",
    "    theta_set.append(np.concatenate([theta_a,theta_v]))\n",
    "    print(\"Subject \", i)\n",
    "    print(\"Converged:\",success, \"NLL:\",objective)\n",
    "    print(\"theta_a\", theta_a)\n",
    "    print(\"theta_v\", theta_v)\n",
    "    p_a = np.array([baseline_softmax(theta) for theta in theta_a]).reshape(-1,1)\n",
    "    p_v = np.array([baseline_softmax(theta) for theta in theta_v]).reshape(-1,1)\n",
    "    p_av = (p_a @ p_v.T) / (p_a @ p_v.T + (1 - p_a) @ (1 - p_v).T)\n",
    "    p_set.append(np.vstack([p_a.T, p_v.T, p_av]))\n",
    "    print(\"===\")\n",
    "    print(\"p_a\", p_a.flatten())\n",
    "    print(\"p_v\", p_v.flatten())\n",
    "    print(\"p_av\\n\", np.round(p_av, 3))\n",
    "    print(\"===\")\n",
    "    print(\"data\")\n",
    "    print(np.round(binom.pmf(data[i][2:], 24, p_av), 3))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = p_set\n",
    "y = list(data/24)\n",
    "\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for idx in range(5):\n",
    "    ax1.scatter(x[idx], y[idx],s=160,label=idx+1)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"FLMP response probabilities vs. the response proportions\",fontsize=20)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\\\\\\\n\".join([f\"Subject {i+1} & \" + \" & \".join(np.char.mod('%.2f', x)) for i, x in enumerate(p_set)]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d8026c75a4908d7e0e048edfdade2cb3b8819d75b067a00cc154c2b5f826605"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
