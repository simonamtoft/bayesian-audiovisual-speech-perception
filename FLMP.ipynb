{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a FLMP\n",
    "In this notebook, we will fit a Fuzzy Logical Model of Perception (FLMP) to audiovisual speech perception data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "from scipy.special import comb\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import minimize, LinearConstraint, Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "The data consists of five text files, each containing seven rows and five columns, where:\n",
    "- Row 1: Audiotorial data\n",
    "- Row 2: Visual data\n",
    "- Rows 3-7: Audiovisual data\n",
    "    - a combination of rows 1 and 2\n",
    "    - visual goes from 'b' (row 3) to 'd' (row 7) \n",
    "    - audio goes from 'b' (col 1) to 'd' (col 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data files\n",
    "file_paths = glob(\"./data/*.txt\")\n",
    "\n",
    "# load all data into a single array\n",
    "data = np.array([np.loadtxt(fname) for fname in file_paths])\n",
    "N, M, K = data.shape\n",
    "\n",
    "# define number of samples for each subject\n",
    "n_samples = 24 \n",
    "\n",
    "# split into the three different data types\n",
    "# data_A = data[:, 0, :]\n",
    "# data_V = data[:, 1, :]\n",
    "# data_AV = data[:, 2:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit FLMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create softmax function\n",
    "def baseline_softmax(x):\n",
    "    x = np.concatenate([\n",
    "        np.array([x]).flatten(), [0]\n",
    "    ])\n",
    "    e = np.exp(x)\n",
    "    return e / e.sum()\n",
    "\n",
    "# create our own pmf function\n",
    "def binomial_pmf(k, n, p):\n",
    "    return comb(n, k) * np.power(p, k) * np.power(1 - p, n - k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(theta, data, n_samples=24):\n",
    "    # extract audio and visual parameters\n",
    "    # theta_A = theta[0:(K-1)]\n",
    "    # theta_V = theta[(K-1): ]\n",
    "    theta_A = theta[0:K]\n",
    "    theta_V = theta[K: ]\n",
    "\n",
    "    # get probabilities for audio and visual\n",
    "    # p_A = baseline_softmax(theta_A).reshape(-1,1)\n",
    "    # p_V = baseline_softmax(theta_V).reshape(-1,1)\n",
    "    p_A = np.array([baseline_softmax(t)[0] for t in theta_A]).reshape(-1,1)\n",
    "    p_V = np.array([baseline_softmax(t)[0] for t in theta_V]).reshape(-1,1)\n",
    "    \n",
    "    # compute audiovisual probabilities by\n",
    "    # taking the outer product for all combinations of audio and visual\n",
    "    p_AV = (p_A @ p_V.T) / (p_A @ p_V.T + (1 - p_A) @ (1 - p_V).T)\n",
    "    \n",
    "    # compute the log-likelihoods\n",
    "    probs = np.vstack([p_A.T, p_V.T, p_AV])\n",
    "    L = np.log(binomial_pmf(data, n_samples, probs)).sum()\n",
    "    # L_A = binom.logpmf(data[0], n_samples, p_A).flatten()\n",
    "    # L_V = binom.logpmf(data[1], n_samples, p_V).flatten()\n",
    "    # L_AV = binom.logpmf(data[2:], n_samples, p_AV).flatten()\n",
    "    # L = np.concatenate([L_A, L_V, L_AV]).sum()\n",
    "\n",
    "    # return the negative log-likelihood\n",
    "    return -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flmp_fit(data, n_samples):\n",
    "    \"\"\"Perform FLMP fit to data\"\"\"\n",
    "    # K_ = K - 1\n",
    "    K_ = K\n",
    "    theta = np.zeros(K_*2)\n",
    "    opt_result = minimize(objective_function, theta, args=(data, n_samples))\n",
    "    objective, theta_A, theta_V = (\n",
    "        opt_result.fun, \n",
    "        (opt_result.x[0:K_]), \n",
    "        (opt_result.x[K_:])\n",
    "    )\n",
    "    return objective, theta_A, theta_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for subject 1\n",
      "Negative log-likelihood: 70.25765786050826\n",
      "Audio: [-4.78771542 -1.95605364 -0.25823502  1.43526796  1.67202829]\n",
      "Visual: [-1.11834396  0.51165128  1.54670804  4.28161049  5.03519686]\n",
      "\n",
      "Results for subject 2\n",
      "Negative log-likelihood: 41.7976564702329\n",
      "Audio: [-6.55473261 -1.91458401  0.34489206  3.09946715  3.87804737]\n",
      "Visual: [-1.6323042   1.07303217  2.55000152  4.14860438  6.12230226]\n",
      "\n",
      "Results for subject 3\n",
      "Negative log-likelihood: 68.33041239058295\n",
      "Audio: [-2.95926905 -1.13433544 -0.10648988  1.29981559  1.60598464]\n",
      "Visual: [-1.53452301 -0.3698892   0.86865851  3.57910917  5.65092501]\n",
      "\n",
      "Results for subject 4\n",
      "Negative log-likelihood: 72.3148065626844\n",
      "Audio: [-2.66352712 -1.96654471 -1.27082507  0.82708934  1.69431479]\n",
      "Visual: [-3.69983135 -2.16532762 -1.17804284  2.62584348  4.25103027]\n",
      "\n",
      "Results for subject 5\n",
      "Negative log-likelihood: 73.02387779051162\n",
      "Audio: [-4.43200284 -2.15618122 -0.97970257  0.64690831  1.04513991]\n",
      "Visual: [-3.56948525 -1.18540161  1.06838789  4.37877927  7.72373571]\n"
     ]
    }
   ],
   "source": [
    "# perform FLMP fit for each subject\n",
    "theta_A = np.zeros((K, N))\n",
    "theta_V = np.zeros((K, N))\n",
    "neg_L = np.zeros(K)\n",
    "for i in range(K):\n",
    "    obj, tA, tV = flmp_fit(data[i], n_samples)\n",
    "\n",
    "    # save results\n",
    "    neg_L[i] = obj\n",
    "    theta_A[i, :] = tA \n",
    "    theta_V[i, :] = tV\n",
    "    # theta_A[i, :-1] = tA\n",
    "    # theta_V[i, :-1] = tV\n",
    "\n",
    "    # print results\n",
    "    print(f'\\nResults for subject {i+1}')\n",
    "    print(f'Negative log-likelihood: {neg_L[i]}')\n",
    "    print(\"Audio:\", theta_A[i])\n",
    "    print(\"Visual:\", theta_V[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dda45a9d22a65c6dd93109812598142693932f67fb0d1052fe9dfaed030e2fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
